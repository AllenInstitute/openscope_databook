{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85548fe0",
   "metadata": {},
   "source": [
    "# Identifying Regions of Interest with Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04105449",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "⚠️**Note: If running on a new environment, run this cell once and then restart the kernel**⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4797393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "c:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from dandi_utils import dandi_download_open\n",
    "except:\n",
    "    !git clone https://github.com/AllenInstitute/openscope_databook.git\n",
    "    %cd openscope_databook\n",
    "    %pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ce98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import suite2p\n",
    "import numpy as np\n",
    "from tifffile import imsave"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ef59305",
   "metadata": {},
   "source": [
    "### Downloading Ophys NWB Files\n",
    "Here you can download several files for a subject that you can run nway matching on. The pipeline can take in any number of input *sessions*, however, the input ophys data should be from the same imaging plane of the same subject. To specify your own file to use, set `dandiset_id` to be the dandiset id of the files you're interested in. Also set `input_dandi_filepaths` to be a list of the filepaths on dandi of each file you're interested in providing to **Nway Matching**. When accessing an embargoed dataset, set `dandi_api_key` to be your DANDI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4511768",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = \"000336\"\n",
    "dandi_filepath = \"sub-634402/sub-634402_ses-1209063020-acq-1209359211raw_ophys.nwb\"\n",
    "dandi_api_key = os.environ[\"DANDI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be05d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "Opening file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hdmf\\spec\\namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.0 because version 1.5.1 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hdmf\\spec\\namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.3.0 because version 2.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hdmf\\spec\\namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.1.0 because version 0.2.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    }
   ],
   "source": [
    "io = dandi_download_open(dandiset_id, dandi_filepath, \"./\", dandi_api_key=dandi_api_key)\n",
    "# from pynwb import NWBHDF5IO\n",
    "# io = NWBHDFIO(\"./sub-661749_ses-1254161187-acq-1254305759raw_ophys.nwb\", load_namespaces=True)\n",
    "nwb = io.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c9743",
   "metadata": {},
   "source": [
    "### Preparing Suite2P Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a508b006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 540,  499,  485, ...,  516,  534,  503],\n",
       "        [ 520, 1422,  507, ...,  523,  509,  549],\n",
       "        [ 760,  574,  488, ...,  808,  522, 1156],\n",
       "        ...,\n",
       "        [1198,  989,  522, ...,  677,  512,  459],\n",
       "        [ 482,  498,  871, ..., 1739,  615,  506],\n",
       "        [1018,  506,  498, ...,  506,  539,  506]],\n",
       "\n",
       "       [[1347, 1978, 1033, ...,  500,  536, 2126],\n",
       "        [1136,  521,  712, ...,  492,  858, 2157],\n",
       "        [ 441,  540,  995, ...,  447,  502, 2129],\n",
       "        ...,\n",
       "        [ 505, 1366,  480, ...,  863,  507, 2800],\n",
       "        [ 494,  753,  831, ..., 1173,  461,  497],\n",
       "        [ 442,  565,  551, ...,  512,  532, 1989]],\n",
       "\n",
       "       [[ 965,  550, 1295, ..., 1420,  506,  538],\n",
       "        [ 539,  503, 1820, ..., 1570, 1455,  554],\n",
       "        [ 502,  506,  517, ...,  453,  528,  867],\n",
       "        ...,\n",
       "        [1058,  515,  548, ..., 1085,  628,  481],\n",
       "        [ 474,  547,  666, ...,  530,  495, 1378],\n",
       "        [1064,  475,  501, ...,  532, 1646,  519]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 499,  682,  481, ..., 3110,  724, 2230],\n",
       "        [ 537,  516,  539, ...,  492, 1424,  484],\n",
       "        [ 507,  534,  565, ...,  508,  521,  474],\n",
       "        ...,\n",
       "        [1190,  485,  493, ...,  507,  479,  622],\n",
       "        [ 525,  909, 2167, ..., 1599,  506, 1539],\n",
       "        [2440,  525,  785, ..., 1842, 2721, 1016]],\n",
       "\n",
       "       [[2227,  551, 1359, ..., 1024, 1116,  473],\n",
       "        [ 481,  705,  511, ..., 1347,  496,  487],\n",
       "        [ 477,  539,  508, ...,  498,  515,  508],\n",
       "        ...,\n",
       "        [2553, 1394,  623, ...,  465, 2298,  498],\n",
       "        [1464,  774, 1701, ...,  517,  516,  836],\n",
       "        [ 490,  928,  478, ...,  492,  961,  485]],\n",
       "\n",
       "       [[ 643, 1342,  513, ...,  523,  552,  539],\n",
       "        [1035, 2669, 1428, ..., 2650, 1213,  769],\n",
       "        [ 879,  522,  536, ...,  487,  516, 1188],\n",
       "        ...,\n",
       "        [ 524, 1294,  544, ..., 2150,  501,  748],\n",
       "        [ 458,  496,  538, ..., 1145,  522,  491],\n",
       "        [ 469, 2681,  750, ..., 1119,  484,  854]]], dtype=uint16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = np.array(nwb.acquisition[\"raw_suite2p_motion_corrected\"].data).astype(np.uint16)\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ab6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carter.peene\\AppData\\Local\\Temp\\ipykernel_16040\\2967565980.py:1: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  imsave(\"movie.tiff\", movie)\n"
     ]
    }
   ],
   "source": [
    "imsave(\"movie.tiff\", movie)\n",
    "# image_file = image_file.convert(\"L\")\n",
    "# image_file.save(f\"./2p_movie.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e8e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"./results/\"\n",
    "scratch_folder = \"./results/\"\n",
    "input_movie_path = \"./movie\"\n",
    "# sampling_rate = nwb.acquisition[\"raw_suite2p_motion_corrected\"].rate\n",
    "sampling_rate = 100\n",
    "suite2p_threshold_scaling = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a7165",
   "metadata": {},
   "source": [
    "### Running Suite2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996603aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_path': ['./']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tif\n",
      "** Found 1 tifs - converting to binary **\n",
      "NOTE: ScanImageTiffReader not installed, using tifffile\n",
      "2000 frames of binary, time 5.63 sec.\n",
      "4000 frames of binary, time 10.13 sec.\n",
      "6000 frames of binary, time 14.78 sec.\n",
      "8000 frames of binary, time 19.30 sec.\n",
      "10000 frames of binary, time 23.72 sec.\n",
      "12000 frames of binary, time 28.17 sec.\n",
      "14000 frames of binary, time 32.47 sec.\n",
      "16000 frames of binary, time 36.84 sec.\n",
      "18000 frames of binary, time 41.32 sec.\n",
      "20000 frames of binary, time 45.77 sec.\n",
      "22000 frames of binary, time 50.03 sec.\n",
      "24000 frames of binary, time 54.46 sec.\n",
      "26000 frames of binary, time 59.02 sec.\n",
      "28000 frames of binary, time 63.48 sec.\n",
      "30000 frames of binary, time 68.11 sec.\n",
      "32000 frames of binary, time 72.60 sec.\n",
      "34000 frames of binary, time 77.02 sec.\n",
      "36000 frames of binary, time 81.69 sec.\n",
      "38000 frames of binary, time 86.18 sec.\n",
      "40000 frames of binary, time 90.57 sec.\n",
      "42000 frames of binary, time 95.12 sec.\n",
      "44000 frames of binary, time 99.77 sec.\n",
      "time 101.58 sec. Wrote 44201 frames per binary for 1 planes\n",
      ">>>>>>>>>>>>>>>>>>>>> PLANE 0 <<<<<<<<<<<<<<<<<<<<<<\n",
      "NOTE: not running registration, ops['do_registration']=0\n",
      "binary path: ./results/suite2p\\plane0\\data.bin\n",
      "NOTE: Applying builtin classifier at C:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\suite2p\\classifiers\\classifier.npy\n",
      "----------- ROI DETECTION\n",
      "Binning movie in chunks of length 70\n",
      "Binned movie of size [631,512,512] created in 61.74 sec.\n",
      "NOTE: estimated spatial scale ~12 pixels, time epochs 1.00, threshold 10.00 \n",
      "0 ROIs, score=92.73\n",
      "Detected 68 ROIs, 13.53 sec\n",
      "After removing overlaps, 61 ROIs remain\n",
      "----------- Total 75.68 sec.\n",
      "----------- EXTRACTION\n",
      "Masks created, 0.55 sec.\n",
      "Extracted fluorescence from 61 ROIs in 44201 frames, 137.83 sec.\n",
      "----------- Total 138.62 sec.\n",
      "----------- CLASSIFICATION\n",
      "['npix_norm', 'compact', 'skew']\n",
      "----------- SPIKE DECONVOLUTION\n",
      "----------- Total 0.18 sec.\n",
      "Plane 0 processed in 214.91 sec (can open in GUI).\n",
      "total = 317.41 sec.\n",
      "Saving in nwb format\n",
      "root pynwb.file.NWBFile at 0x2394414626560\n",
      "Fields:\n",
      "  file_create_date: [datetime.datetime(2023, 8, 4, 11, 51, 28, 823401, tzinfo=tzlocal())]\n",
      "  identifier: ./\n",
      "  session_description: suite2p_proc\n",
      "  session_start_time: 2023-08-04 11:47:53.036728-07:00\n",
      "  timestamps_reference_time: 2023-08-04 11:47:53.036728-07:00\n",
      "\n",
      "TOTAL RUNTIME 319.27 sec\n"
     ]
    }
   ],
   "source": [
    "ops = suite2p.default_ops()\n",
    "ops['threshold_scaling'] = suite2p_threshold_scaling\n",
    "ops['fs'] = float(sampling_rate) # sampling rate of recording, determines binning for cell detection\n",
    "ops['tau'] = 0.7 # timescale of gcamp to use for deconvolution\n",
    "ops['do_registration'] = 0 # data was already registered\n",
    "ops['save_NWB'] = 1\n",
    "ops['save_folder'] = results_folder\n",
    "ops['fast_disk'] = scratch_folder\n",
    "\n",
    "db = {\n",
    "'data_path': [\"./\"]\n",
    "}\n",
    "output_ops = suite2p.run_s2p(ops=ops, db=db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528c05d",
   "metadata": {},
   "source": [
    "### Suite2P Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1553a896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 44201)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flr_trace = np.load(\"./results/plane0/F.npy\")\n",
    "flr_trace.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cec5cd",
   "metadata": {},
   "source": [
    "- download NWB\n",
    "- save raw movie\n",
    "- determine inputs\n",
    "- run suite2p pipeline\n",
    "- parse output\n",
    "- compare to segmentation in NWB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
