{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Neuropixel Probe Locations\n",
    "It can be handy to know the location and trajectory of the probes that obtain the data. Some NWB files have an **electrodes** field which store these locations. To be more precise, they contain arrays of *CCF* coordinates. [CCF](https://community.brain-map.org/t/allen-mouse-ccf-accessing-and-using-related-data-and-tools/359) is a framework which represents locations in the brain with coordinates that are relative to brain structure. This notebook uses CCF coordinate data in an extracellular electrophysiology NWB file to render the locations of the [Neuropixel](https://www.neuropixels.org/probe) probes that were used.\n",
    "\n",
    "To be able to render locations in a brain, you don't need to know how CCF works except that it is a system of coordinates. We use the **[ccf-widget](https://github.com/NeurodataWithoutBorders/ccf-widget)** library to 3D render the brain and the probe coordinates."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if running on Google Colab, run this cell once, then restart the runtime and run the rest of the notebook\n",
    "import os\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    !git clone https://github.com/AllenInstitute/openscope_databook.git\n",
    "    %cd openscope_databook\n",
    "    %pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ccfwidget import CCFWidget\n",
    "from dandi_utils import dandi_download_open"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Ecephys File\n",
    "If you don't already have a file to analyze, you can use a file from The Allen Institute's **Visual Coding - Neuropixels** dataset. If you want to choose your own file to download, set `dandiset_id` and `dandi_filepath` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = \"000021\"\n",
    "dandi_filepath = \"sub-730756767/sub-730756767_ses-757970808.nwb\"\n",
    "download_loc = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.55.1) of dandi/dandi-cli is available. You are using 0.46.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "Opening file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.5.1 is already loaded.\n",
      "Ignoring cached namespace 'core' version 2.2.2 because version 2.5.0 is already loaded.\n"
     ]
    }
   ],
   "source": [
    "# This can sometimes take a while depending on the size of the file\n",
    "io = dandi_download_open(dandiset_id, dandi_filepath, download_loc)\n",
    "nwb = io.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting NWB CCF Coordinates\n",
    "Here, you can read the NWB file you're interested in viewing. Specify your file of interest's relative file path in `nwb_filepath`. From there, the file will be read and the probe unit coordinates will be extracted and turned into a numpy array.\n",
    "\n",
    "Note that this will only work with ecephys NWB files which have a valid *electrodes* field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the x,y,z ccf coordinates and generate points\n",
    "xs = nwb.electrodes.x\n",
    "ys = nwb.electrodes.y\n",
    "zs = nwb.electrodes.z\n",
    "n = min(len(xs), len(ys), len(zs))\n",
    "points = np.array([[xs[i], ys[i], zs[i]] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 3)\n"
     ]
    }
   ],
   "source": [
    "print(points.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "Rendering is as simple as generating the widget and displaying it. This will create embedded window with the interactive 3D rendering of your scene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf = CCFWidget(markers=[points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0c2f85b2664ed8b3db8896996733fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCFWidget(children=(VBox(children=(Viewer(background=(0.85, 0.85, 0.85), camera=array([[ 1.3441567e+03, -2.172â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ccf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
