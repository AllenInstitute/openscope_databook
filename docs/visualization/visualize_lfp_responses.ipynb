{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3ac1e7",
   "metadata": {},
   "source": [
    "# Visualizing LFP Responses to Stimulus\n",
    "A very useful view when working with ecephys data is the **LFP trace**. LFP, or Local Field Potential, is the electrical potential recorded in the extracellular space in brain tissue, and represents activity in regions of neurons. This is particularly useful when you examine LFP responses to stimulus events. The type of stimulus can vary, but in order to visualize this, you must have access to the times of the stimulus events you're interested in. In this notebook, you can extract stimulus times from *spike_times.nwb* and LFP data from *probeA_lfp.nwb*, or a similar file. Importantly, since the stimulus timestamps and the LFP timestamps are not likely to be aligned with each other and in perfectly regular intervals, they must be interpolated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410df685",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbff7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874b37c",
   "metadata": {},
   "source": [
    "### Downloading NWB Files\n",
    "If you don't already have files to analyze, you can use data from The Allen Institute's `Visual Coding - Neuropixels` dataset. If you want to choose your own files to download, set `dandiset_id`, `dandi_stim_filepath`, `dandi_lfp_filepath` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01caed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = \"000021\"\n",
    "dandi_stim_filepath = \"\"\n",
    "dandi_lfp_filepath = \"\"\n",
    "download_loc = \"~/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dandiset = dandiapi.DandiAPIClient().get_dandiset(dandiset_id)\n",
    "file = my_dandiset.get_asset_by_path(filepath)\n",
    "filename = filepath.split(\"/\")[-1]\n",
    "# this may take awhile, especially if the file to download is large\n",
    "file.download(f\"{download_loc}/{filename}\")\n",
    "\n",
    "print(f\"Downloaded file to {download_loc}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413a777",
   "metadata": {},
   "source": [
    "### Extracting Stimulus Times\n",
    "First, you must take the stimulus table from your stimulus file. Since your stimulus table will be unique to your experiment, you'll have to use some ingenuity to extract the timestamps that are of interest to you. Below, we display your stimulus names. Set `stim_name` to be the name that contains the associated stimulus table you want. Then we display the stimulus table. You can see that it contains the `start_time` of each stimulus event. In the commented cell below showing `extract timestamps for given stimulus frame`, you should write code to iterate through this table and filter all but the rows that contain an important stimulus event. The output should be a list of timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_filepath = f\"{download_loc}/{filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19235113",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_io = NWBHDF5IO(stim_filepath, mode=\"r\", load_namespaces=True)\n",
    "stim_file = stim_io.read() \n",
    "stimulus_names = list(stim_file.intervals.keys())\n",
    "print(stimulus_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8292f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stim_name = \"Stimulus Name\"\n",
    "stim_table = stim_file.intervals[stim_name]\n",
    "print(len(stim_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88960ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract timestamps for given stimulus frame\n",
    "\n",
    "# def cond(x):\n",
    "#         return True\n",
    "\n",
    "# filtered_stim_rows = list(filter(cond, stim_table))\n",
    "# stim_timestamps = [float(row.start_time) for row in filtered_stim_rows]\n",
    "# print(stim_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0806c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stim_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f0366",
   "metadata": {},
   "source": [
    "### LFP Interpolation\n",
    "After you have a valid list of stimulus timestamps, you can extract the `LFP.data` and associated `LFP.timestamps`. With these, you can generate a regular timestamp array called `time_axis`, and interpolate the LFP data along it, making interpolated LFP data called `interp_lfp`. This should be a 2D array with dimensions `time` and `channel`, where channels are the different measurement channels along the probe. Here, the timestamps are interpolated to 1000 Hz, but you can change this by setting `interp_hz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d529b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_filepath = f\"{download_loc}/{filename}\"\n",
    "interp_hz = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fde9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_io = NWBHDF5IO(lfp_filepath, mode=\"r\", load_namespaces=True)\n",
    "lfp_file = lfp_io.read()\n",
    "lfp = lfp_file.acquisition[\"probe_0_lfp_data\"]\n",
    "\n",
    "print(lfp.timestamps.shape)\n",
    "print(lfp.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312fa5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ensure we don't go out of bounds on either timestamps array\n",
    "stop_time = min(lfp.timestamps[-1], stim_timestamps[-1])\n",
    "# generate regularly-space x values and interpolate along it\n",
    "time_axis = np.arange(0, stop_time, step=(1/interp_hz))\n",
    "f = interpolate.interp1d(lfp.timestamps, lfp.data, axis=0, kind=\"nearest\", fill_value=\"extrapolate\")\n",
    "interp_lfp = f(time_axis)\n",
    "\n",
    "print(interp_lfp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ffd2f",
   "metadata": {},
   "source": [
    "### Getting Stimulus Time Windows\n",
    "Now that you have your interpolated LFP data, you can use the stimulus times to identify the windows of time in the LFP data that exist around a stimulus event. Set `start_time` to be a negative integer, representing the number of seconds before the stimulus event and `end_time` to be number of milliseconds afterward. Then the `windows` array will be generated as a set of slices of the `interp_lfp` trace by using `interp_hz` to convert seconds to array indices. These will be averaged out for each measurement channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = -20\n",
    "end_time = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1455187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get event windows\n",
    "\n",
    "windows = []\n",
    "for stim_ts in stim_timestamps:\n",
    "    # convert time to index\n",
    "    start_idx = int(stim_ts*interp_hz) + start_time\n",
    "    end_idx = int(stim_ts*interp_hz) + end_time\n",
    " \n",
    "    # bounds checking\n",
    "    if start_idx < 0 or end_idx > len(intp_lfp)-1:\n",
    "        continue\n",
    "        \n",
    "    windows.append(interp_lfp[start_idx:end_idx])\n",
    "\n",
    "windows = np.array(windows)\n",
    "print(windows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average of all windows\n",
    "\n",
    "average_trace = np.average(windows, axis=0)\n",
    "average_trace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get standard deviation for confidence interval\n",
    "\n",
    "n = windows.shape[1]\n",
    "# ci = np.std(windows, axis=0) / sqrt(n)\n",
    "ci = np.std(windows, axis=0) / 2\n",
    "ci.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c84604",
   "metadata": {},
   "source": [
    "### Visualizing LFP Traces\n",
    "Now you have the averaged LFP traces for each channel. Below are three views of the same data. There are many channels to view, so for convenience, you can view just a subset of all the channels. You can set `start_channel` and `end_channel` to the bounds of the subset you want to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b826e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of channels\n",
    "print(average_trace.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf03e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_channel = 0\n",
    "end_channel = average_trace.shape[1]\n",
    "n_channels = end_channel - start_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb842989",
   "metadata": {},
   "source": [
    "#### Traces from Channels Overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafaa9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xaxis = np.arange(start_time, end_time)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(xaxis, average_trace[:,start_channel:end_channel])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053a756",
   "metadata": {},
   "source": [
    "#### Traces from Channels Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948130b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xaxis = np.arange(start_time, end_time)\n",
    "fig, ax = plt.subplots(figsize=(8, n_channels))\n",
    "\n",
    "for channel in range(start_channel, end_channel):\n",
    "    offset_idx = channel-start_channel\n",
    "    offset_trace = average_trace[:,channel] + 0.0001*offset_idx\n",
    "    ax.plot(xaxis, offset_trace)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ea3b7",
   "metadata": {},
   "source": [
    "#### Traces from Channels with Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362a584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xaxis = np.arange(start_time, end_time)\n",
    "fig, axs = plt.subplots(n_channels, 2, figsize=(16, n_channels*2))\n",
    "\n",
    "for i in range(n_channels):\n",
    "    for j in range(2):\n",
    "        channel = start_channel + i\n",
    "\n",
    "        axs[i][j].plot(xaxis, average_trace[:,channel])\n",
    "        upper_bound = average_trace + (ci)\n",
    "        lower_bound = average_trace - (ci)\n",
    "        axs[i][j].fill_between(xaxis, lower_bound[:,channel], upper_bound[:,channel], color='b', alpha=.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
