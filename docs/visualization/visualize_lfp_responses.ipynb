{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3ac1e7",
   "metadata": {},
   "source": [
    "# Visualizing LFP Responses to Stimulus\n",
    "A very useful view when working with ecephys data is the **LFP trace**. LFP, or Local Field Potential, is the electrical potential recorded in the extracellular space in brain tissue, and represents activity in regions of neurons. This is particularly useful when you examine LFP responses to stimulus events. The type of stimulus can vary, but in order to visualize this, you must have access to the times of the stimulus events you're interested in. In this notebook, you can extract stimulus times from *spike_times.nwb* and LFP data from *probeA_lfp.nwb*, or a similar file. Importantly, since the stimulus timestamps and the LFP timestamps are not likely to be aligned with each other and in perfectly regular intervals, they must be interpolated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410df685",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbff7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c58a4",
   "metadata": {},
   "source": [
    "### Read NWB Files\n",
    "You can rename the filepaths below to suit your purposes. It is likely that you will need separate files for the stimulus data and the LFP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_filepath = \"your/filepath/spike_times.nwb\"\n",
    "lfp_filepath = \"your/filepath/probeA_lfp.nwb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_io = NWBHDF5IO(lfp_filepath, mode=\"r\", load_namespaces=True)\n",
    "lfp_file = lfp_io.read()\n",
    "stim_io = NWBHDF5IO(stim_filepath, mode=\"r\", load_namespaces=True)\n",
    "stim_file = stim_io.read() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413a777",
   "metadata": {},
   "source": [
    "### Extract Stimulus Times\n",
    "First, you must take the stimulus table from your stimulus file. Since your stimulus table will be unique to your experiment, you'll have to use some ingenuity to extract the timestamps that are of interest to you. Below, we display your stimulus names. Set `stim_name` to be the name that contains the associated stimulus table you want. Then we display the stimulus table. You can see that it contains the `start_time` of each stimulus event. In the commented cell below showing `extract timestamps for given stimulus frame`, it is recommended that write code to iterate through this table and filter all but the rows that contain an important stimulus event. The output should be a list of timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19235113",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_names = list(stim_file.intervals.keys())\n",
    "print(stimulus_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8292f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stim_name = \"ICkcfg0_presentations\"\n",
    "stim_table = stim_file.intervals[stim_name]\n",
    "print(len(stim_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88960ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract timestamps for given stimulus frame\n",
    "\n",
    "# def cond(x):\n",
    "#         return float(x.orientation) == 135.0\n",
    "\n",
    "# filtered_stim_rows = list(filter(cond, stim_table))\n",
    "\n",
    "# stim_timestamps = [float(row.start_time) for row in filtered_stim_rows]\n",
    "# print(stim_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0806c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stim_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f0366",
   "metadata": {},
   "source": [
    "### LFP Interpolation\n",
    "After you have a valid list of stimulus timestamps, you can extract the `LFP.data` and associated `LFP.timestamps`. With these, you can generate a regular timestamp array called `time_axis`, and interpolate the LFP data along it, making interpolated LFP data called `intp_lfp`. This should be a 2D array with dimensions `time` and `channel`, where channels are the different measurement channels along the probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp = lfp_file.acquisition[\"probe_0_lfp_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_time = min(lfp.timestamps[-1],stim_timestamps[-1])\n",
    "time_axis = np.arange(0,stop_time,step=0.001)\n",
    "print(len(time_axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1e8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lfp.timestamps.shape)\n",
    "print(lfp.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312fa5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = interpolate.interp1d(lfp.timestamps, lfp.data, axis=0, kind=\"nearest\", fill_value=\"extrapolate\")\n",
    "intp_lfp = f(time_axis)\n",
    "print(intp_lfp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ffd2f",
   "metadata": {},
   "source": [
    "### Get Stimulus Time Windows\n",
    "Now that you have your interpolated LFP data, you can use the stimulus times to identify the slices of the LFP that exist around a stimulus event. Set `start_time` to be a negative integer, representing the number of seconds before the stimulus event and `end_time` to be number of milliseconds afterward. Then the `windows` array will be generated as a set of slices of the `intp_lfp` trace. These will be averaged out for each measurement channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = -20\n",
    "end_time = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1455187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get event windows\n",
    "\n",
    "windows = []\n",
    "for stim_ts in stim_timestamps:\n",
    "    start_idx = int(stim_ts*1000) + start_time\n",
    "    end_idx = int(stim_ts*1000) + end_time\n",
    "    if start_idx < 0 or end_idx > len(intp_lfp)-1:\n",
    "        continue\n",
    "        \n",
    "    windows.append(intp_lfp[start_idx:end_idx])\n",
    "\n",
    "windows = np.array(windows)\n",
    "print(windows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average of all windows\n",
    "\n",
    "average_trace = np.average(windows, axis=0)\n",
    "average_trace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get standard deviation for confidence interval\n",
    "\n",
    "n = windows.shape[1]\n",
    "# ci = np.std(windows, axis=0) / sqrt(n)\n",
    "ci = np.std(windows, axis=0) / 2\n",
    "ci.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c84604",
   "metadata": {},
   "source": [
    "### LFP Visualization\n",
    "Now you have the averaged LFP traces for each channel. Below are three views of the same data. There are many channels to view, so for convenience, you can view just a subset of all the channels. You can set `start_channel` and `end_channel` to the bounds of the subset you want to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b826e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of channels\n",
    "print(average_trace.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf03e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_channel = 0\n",
    "end_channel = average_trace.shape[1]\n",
    "n_channels = end_channel - start_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb842989",
   "metadata": {},
   "source": [
    "#### Traces from channels overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafaa9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xaxis = np.arange(start_time, end_time)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(xaxis, average_trace[:,start_channel:end_channel])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053a756",
   "metadata": {},
   "source": [
    "#### Traces from channels stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948130b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xaxis = np.arange(start_time, end_time)\n",
    "fig, ax = plt.subplots(figsize=(8, n_channels))\n",
    "\n",
    "for channel in range(start_channel, end_channel):\n",
    "    offset_idx = channel-start_channel\n",
    "    offset_trace = average_trace[:,channel] + 0.0001*offset_idx\n",
    "    ax.plot(xaxis, offset_trace)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ea3b7",
   "metadata": {},
   "source": [
    "#### Traces from channels with confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362a584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xaxis = np.arange(start_time, end_time)\n",
    "fig, axs = plt.subplots(n_channels, 2, figsize=(16, n_channels*2))\n",
    "\n",
    "for i in range(n_channels):\n",
    "    for j in range(2):\n",
    "        channel = start_channel + i\n",
    "\n",
    "        axs[i][j].plot(xaxis, average_trace[:,channel])\n",
    "        upper_bound = average_trace + (ci)\n",
    "        lower_bound = average_trace - (ci)\n",
    "        axs[i][j].fill_between(xaxis, lower_bound[:,channel], upper_bound[:,channel], color='b', alpha=.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
