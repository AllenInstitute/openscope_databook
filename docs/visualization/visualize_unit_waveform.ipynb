{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09650a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.visualization import plot_mean_waveforms, plot_spike_counts, raster_plot\n",
    "from dandi import dandiapi\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_filepath = f\"../../../data/visual_coding/sub-699733573_ses-715093703.nwb\"\n",
    "stim_io = NWBHDF5IO(stim_filepath, mode=\"r\", load_namespaces=True)\n",
    "stim_file = stim_io.read() \n",
    "units = stim_file.units.to_dataframe()\n",
    "units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "units.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34188b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "units.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_units = units[units.quality == 'good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009266d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting units by quality or other attribute (or firing rate?)\n",
    "# plot spike times for units\n",
    "# show average waveform across units (possibly in different brain areas?)\n",
    "# selection of unit\n",
    "# showing waveform\n",
    "# for unit, plot firing rate over time or drift\n",
    "# show unit location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2334f",
   "metadata": {},
   "source": [
    "### Showing Spike Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def presentationwise_spike_counts(\n",
    "        self,\n",
    "        bin_edges,\n",
    "        stimulus_presentation_ids,\n",
    "        unit_ids,\n",
    "        binarize=False,\n",
    "        dtype=None,\n",
    "        large_bin_size_threshold=0.001,\n",
    "        time_domain_callback=None\n",
    "    ):\n",
    "        ''' Build an array of spike counts surrounding stimulus onset per\n",
    "        unit and stimulus frame.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        bin_edges : numpy.ndarray\n",
    "            Spikes will be counted into the bins defined by these edges.\n",
    "            Values are in seconds, relative to stimulus onset.\n",
    "        stimulus_presentation_ids : array-like\n",
    "            Filter to these stimulus presentations\n",
    "        unit_ids : array-like\n",
    "            Filter to these units\n",
    "        binarize : bool, optional\n",
    "            If true, all counts greater than 0 will be treated as 1. This\n",
    "            results in lower storage overhead, but is only reasonable if bin\n",
    "            sizes are fine (<= 1 millisecond).\n",
    "        large_bin_size_threshold : float, optional\n",
    "            If binarize is True and the largest bin width is greater than\n",
    "            this value, a warning will be emitted.\n",
    "        time_domain_callback : callable, optional\n",
    "            The time domain is a numpy array whose values are trial-aligned bin\n",
    "            edges (each row is aligned to a different trial). This optional\n",
    "            function will be applied to the time domain before counting spikes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xarray.DataArray :\n",
    "            Data array whose dimensions are stimulus presentation, unit,\n",
    "            and time bin and whose values are spike counts.\n",
    "\n",
    "        '''\n",
    "\n",
    "        stimulus_presentations = self._filter_owned_df(\n",
    "            'stimulus_presentations',\n",
    "            ids=stimulus_presentation_ids)\n",
    "        units = self._filter_owned_df('units', ids=unit_ids)\n",
    "\n",
    "        largest_bin_size = np.amax(np.diff(bin_edges))\n",
    "        if binarize and largest_bin_size > large_bin_size_threshold:\n",
    "            warnings.warn(\n",
    "                'You\\'ve elected to binarize spike counts, but your maximum '\n",
    "                f'bin width is {largest_bin_size:2.5f} seconds. '\n",
    "                'Binarizing spike counts with such a large bin width can '\n",
    "                'cause significant loss of accuracy! '\n",
    "                'Please consider only binarizing spike counts '\n",
    "                f'when your bins are <= {large_bin_size_threshold} '\n",
    "                'seconds wide.'\n",
    "            )\n",
    "\n",
    "        bin_edges = np.array(bin_edges)\n",
    "        domain = build_time_window_domain(\n",
    "            bin_edges,\n",
    "            stimulus_presentations['start_time'].values,\n",
    "            callback=time_domain_callback)\n",
    "\n",
    "        out_of_order = np.where(np.diff(domain, axis=1) < 0)\n",
    "        if len(out_of_order[0]) > 0:\n",
    "            out_of_order_time_bins = \\\n",
    "                [(row, col) for row, col in zip(out_of_order)]\n",
    "            raise ValueError(\"The time domain specified contains out-of-order \"\n",
    "                             f\"bin edges at indices: {out_of_order_time_bins}\")\n",
    "\n",
    "        ends = domain[:, -1]\n",
    "        starts = domain[:, 0]\n",
    "        time_diffs = starts[1:] - ends[:-1]\n",
    "        overlapping = np.where(time_diffs < 0)[0]\n",
    "\n",
    "        if len(overlapping) > 0:\n",
    "            # Ignoring intervals that overlaps multiple time bins because\n",
    "            # trying to figure that out would take O(n)\n",
    "            overlapping = [(s, s + 1) for s in overlapping]\n",
    "            warnings.warn(\"You've specified some overlapping time intervals \"\n",
    "                          f\"between neighboring rows: {overlapping}, \"\n",
    "                          \"with a maximum overlap of\"\n",
    "                          f\" {np.abs(np.min(time_diffs))} seconds.\")\n",
    "\n",
    "        tiled_data = build_spike_histogram(\n",
    "            domain,\n",
    "            self.spike_times,\n",
    "            units.index.values,\n",
    "            dtype=dtype,\n",
    "            binarize=binarize\n",
    "        )\n",
    "\n",
    "        stim_presentation_id = stimulus_presentations.index.values\n",
    "\n",
    "        tiled_data = xr.DataArray(\n",
    "            name='spike_counts',\n",
    "            data=tiled_data,\n",
    "            coords={\n",
    "                'stimulus_presentation_id': stim_presentation_id,\n",
    "                'time_relative_to_stimulus_onset': (bin_edges[:-1] +\n",
    "                                                    np.diff(bin_edges) / 2),\n",
    "                'unit_id': units.index.values\n",
    "            },\n",
    "            dims=['stimulus_presentation_id',\n",
    "                  'time_relative_to_stimulus_onset',\n",
    "                  'unit_id']\n",
    "        )\n",
    "\n",
    "        return tiled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06602644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to build an array of spike counts surrounding stimulus presentation onset\n",
    "# To do that, we will need to specify some bins (in seconds, relative to stimulus onset)\n",
    "time_bin_edges = np.linspace(-0.01, 0.4, 200)\n",
    "\n",
    "# look at responses to the flash stimulus\n",
    "flash_250_ms_stimulus_presentation_ids = session.stimulus_presentations[\n",
    "    session.stimulus_presentations['stimulus_name'] == 'flashes'\n",
    "].index.values\n",
    "\n",
    "# and get a set of units with only decent snr\n",
    "decent_snr_unit_ids = session.units[\n",
    "    session.units['snr'] >= 1.5\n",
    "].index.values\n",
    "\n",
    "spike_counts_da = session.presentationwise_spike_counts(\n",
    "    bin_edges=time_bin_edges,\n",
    "    stimulus_presentation_ids=flash_250_ms_stimulus_presentation_ids,\n",
    "    unit_ids=decent_snr_unit_ids\n",
    ")\n",
    "spike_counts_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = good_units.spike_times\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "img = ax.imshow(data_array.T, interpolation='none')\n",
    "plt.colorbar(img, cax=cbar_axis)\n",
    "\n",
    "cbar_axis.set_ylabel(cbar_label, fontsize=16)\n",
    "\n",
    "ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "ax.set_ylabel(ylabel, fontsize=16)\n",
    "\n",
    "reltime = np.array(time_coords)\n",
    "ax.set_xticks(np.arange(0, len(reltime), xtick_step))\n",
    "ax.set_xticklabels([f'{mp:1.3f}' for mp in reltime[::xtick_step]], rotation=45)\n",
    "ax.set_xlabel(xlabel, fontsize=16)\n",
    "\n",
    "ax.set_title(title, fontsize=20)\n",
    "\n",
    "return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a45648",
   "metadata": {},
   "source": [
    "### Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_num = 950913039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "units.waveform_mean[950913039].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = np.array([waveform for waveform in units.waveform_mean])\n",
    "waveforms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_waveform = np.average(waveforms,axis=0)\n",
    "avg_waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae54d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# for waveform in waveforms:\n",
    "#     ax.plot(waveform)\n",
    "ax.plot(avg_waveform)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = units.waveform_mean[unit_num]\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b643b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_avg_waveform = np.average(waveform, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdaced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(unit_avg_waveform)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
