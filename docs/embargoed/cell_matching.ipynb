{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85548fe0",
   "metadata": {},
   "source": [
    "# Cell Matching Across Days\n",
    "Experimental sessions are conducted across multiple days on the same mouse. When imaging the brain location on the same plane with **2-Photon Imaging**, the image will not be perfectly identical. The frame may be in a slighlty different location on the brain or at a slighlty different depth. Additionally, cells can move relative to eachother over time. Due to this, computational methods are required to identify which cell *Regions of Interest* (ROIs) are the same as the previous session.\n",
    "\n",
    "We use the Allen Institute's [**Nway Matching**](https://github.com/AllenInstitute/ophys_nway_matching) pipeline for this which is described in more detail below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04105449",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4797393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### if running on Google Colab, run this cell once, then restart the runtime and run the rest of the notebook\n",
    "import os\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    !git clone https://github.com/AllenInstitute/openscope_databook.git\n",
    "    %cd openscope_databook\n",
    "    %pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ce98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dandi_utils import dandi_download_open\n",
    "from PIL import Image\n",
    "from time import sleep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ef59305",
   "metadata": {},
   "source": [
    "### Downloading Ophys NWB Files\n",
    "Here you can download several files for a subject that you can run nway matching on. The pipeline can take in any number of input *sessions*, however, the input ophys data should be from the same imaging plane of the same subject. To specify your own file to use, set `dandiset_id` to be the dandiset id of the files you're interested in. Also set `input_dandi_filepaths` to be a list of the filepaths on dandi of each file you're interested in providing to **Nway Matching**. When accessing an embargoed dataset, set `dandi_api_key` to be your DANDI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4511768",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = \"000336\"\n",
    "dandi_filepath_1 = \"sub-621602/sub-621602_ses-1193555033-acq-1193675753_ophys.nwb\"\n",
    "dandi_filepath_2 = \"sub-621602/sub-621602_ses-1194555869-acq-1194754135_ophys.nwb\"\n",
    "download_loc = \".\"\n",
    "\n",
    "# here, specify the list dandi filepaths of the files you want to run cell matching on\n",
    "# the subject ids should be the same, but the session ids should be different\n",
    "input_dandi_filepaths = [dandi_filepath_1, dandi_filepath_2]\n",
    "\n",
    "dandi_api_key = os.environ[\"DANDI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d78e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.55.1) of dandi/dandi-cli is available. You are using 0.46.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "Opening file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hdmf\\spec\\namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "Opening file\n",
      "File already exists\n",
      "Opening file\n",
      "File already exists\n",
      "Opening file\n"
     ]
    }
   ],
   "source": [
    "ios = [dandi_download_open(dandiset_id, filepath, download_loc, dandi_api_key=dandi_api_key) for filepath in input_dandi_filepaths]\n",
    "nwbs = [io.read() for io in ios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a94b14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# these should be similar values, indicating that the images are from the same imaging plane\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m nwb \u001b[39min\u001b[39;00m nwbs:\n\u001b[1;32m----> 3\u001b[0m     \u001b[39mprint\u001b[39m(nwb\u001b[39m.\u001b[39;49mlab_meta_data[\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mimaging_depth)\n",
      "File \u001b[1;32mc:\\Users\\carter.peene\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hdmf\\utils.py:1009\u001b[0m, in \u001b[0;36mLabelledDict.__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(val)\n\u001b[0;32m   1008\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1009\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'metadata'"
     ]
    }
   ],
   "source": [
    "# these should be similar values, indicating that the images are from the same imaging plane\n",
    "for nwb in nwbs:\n",
    "    print(nwb.lab_meta_data[\"metadata\"].imaging_depth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcb6ebd2",
   "metadata": {},
   "source": [
    "### Generating Cell-Matching Input File\n",
    "The Allen Institute has created a robust pipeline for conducting cell matching between 2 or more sessions called [**Nway Matching**](https://github.com/AllenInstitute/ophys_nway_matching). For those who are inquisitive, the general algorithm is described in page 31 of [{cite}`Garrett2023`](https://www.biorxiv.org/content/10.1101/2023.02.14.528085v2.full.pdf). In summary, the input images are aligned together with a euclidian image registration technique. Then the given input ROI masks are used with the [Blossom Algorithm](https://en.wikipedia.org/wiki/Blossom_algorithm) as a bipartite graph matching algorithm. This identifies which ROIs represent the same cells with high probability.\n",
    "\n",
    "The caveat to using this pipeline is that it requires input in a specific JSON format rather than an NWB File. The following functions are used to generate a file, `input.json`, which can be used to obtain important output. The input json contains an entry for each input experiment. 2 or more experiments can be used. The first experiment is called *fixed* and the other ones are *moving*. For each experiment, a unique experiment ID, a path to the experiment projection image, and a list of objects for each ROI are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15fa825",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for each ROI in an ROI table, create a JSON object containing its information, return a list of JSON objects\n",
    "\n",
    "def make_roi_entries(roi_table):\n",
    "    roi_entries = []\n",
    "    for roi_idx in range(len(roi_table)):\n",
    "        x = int(roi_table[\"x\"][roi_idx])\n",
    "        y = int(roi_table[\"y\"][roi_idx])\n",
    "        height = int(roi_table[\"height\"][roi_idx])\n",
    "        width = int(roi_table[\"width\"][roi_idx])\n",
    "        \n",
    "        mask_subimage = roi_table[\"image_mask\"][roi_idx][y:y+height,x:x+width]\n",
    "        \n",
    "        roi_entry = {\n",
    "            \"id\": int(roi_table[\"id\"][roi_idx]),\n",
    "            \"valid\": bool(roi_table[\"valid_roi\"][roi_idx]),\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"z\": 1,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            # convert 2D array to 2D list of bools\n",
    "            \"mask_matrix\": [[bool(elem) for elem in row] for row in mask_subimage]\n",
    "        }\n",
    "        roi_entries.append(roi_entry)\n",
    "    return roi_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f94206",
   "metadata": {},
   "outputs": [],
   "source": [
    "### take in an image array and return it converted to uint16\n",
    "\n",
    "def normalize_to_16b(image_array):\n",
    "    return image_array.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert an nwb object into a 'experiment' JSON object with the required format\n",
    "\n",
    "def nwb_to_experiment_json(nwb):\n",
    "    # save image here\n",
    "    grayscale_image = np.array(nwb.processing[\"ophys\"][\"images\"][\"average_image\"])\n",
    "    image_array = normalize_to_16b(np.array(grayscale_image))\n",
    "    image_file = Image.fromarray(image_array)\n",
    "    image_file = image_file.convert(\"L\")\n",
    "    image_file.save(f\"./{nwb.identifier}_image.png\")\n",
    "\n",
    "    roi_table = nwb.processing[\"ophys\"][\"image_segmentation\"][\"cell_specimen_table\"]\n",
    "    \n",
    "    experiment = {\n",
    "        \"id\": nwb.identifier, \n",
    "        \"ophys_average_intensity_projection_image\": f\"./{nwb.identifier}_image.png\",\n",
    "        \"cell_rois\": make_roi_entries(roi_table)\n",
    "    }\n",
    "\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make the input json object, populate its experiments field with an experiment object for each nwb object\n",
    "\n",
    "input_exps = {\n",
    "    \"experiment_containers\": {\n",
    "        \"ophys_experiments\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "for nwb in nwbs:\n",
    "    experiment = nwb_to_experiment_json(nwb)\n",
    "    input_exps[\"experiment_containers\"][\"ophys_experiments\"].append(experiment)\n",
    "\n",
    "with open(\"input.json\", \"w\") as f:\n",
    "    json.dump(input_exps, f, indent=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e07d74f6",
   "metadata": {},
   "source": [
    "### Running the Algorithm\n",
    "**Nway Matching** can be run as a command with the following parameters. From there, several output files are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e123156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m nway.nway_matching --input_json input.json --output_json \"./output.json\" --output_dir matching_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43a70c50",
   "metadata": {},
   "source": [
    "### Showing Cell Matching Output\n",
    "The cell matching pipeline outputs the data as a output JSON, and a few plots as `.png` images. The paths to the plots are fetched from the output JSON and displayed below. Additionally, the output json contains a list of matching ROI IDs from each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.json\", \"r\") as f:\n",
    "    output = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78b93d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_plot = Image.open(output[\"nway_warp_summary_plot\"])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(summary_plot)\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fb908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlay_plot = Image.open(output[\"nway_warp_overlay_plot\"])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(overlay_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c59d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fraction_plot = Image.open(output[\"nway_match_fraction_plot\"])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(fraction_plot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfbbfb75",
   "metadata": {},
   "source": [
    "### Visualizing Matching Cells\n",
    "Apart from the image plots above, the main other part of the output is the `nway_matches` list, which contains a list of tuples the contain ROI IDs that *match* between session. The tuples are at most length n, where n is the number of experiments the **Nway Matching** pipeline was given, but some tuples will be shorter if a match wasn't found. The code below uses these tuples of matching IDs, along with the ROI masks in each NWB file's ROI tables, and generates n images that use color to show the matching ROIs between sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes an ROI mask, colors it, adds it onto image\n",
    "def add_color_mask(image, mask, color):\n",
    "    black = [0,0,0]\n",
    "    color_mask = np.array([[(color if boolean else black) for boolean in row] for row in mask])\n",
    "    merged_image = np.where(color_mask!=black, color_mask, image)\n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c59f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a \"random\" color based on n\n",
    "def gen_color(n):\n",
    "    return [n*270 % 255, n*610 % 255, n*890 % 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27012ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the table and image index that an ROI id belongs to\n",
    "def get_image_num(id):\n",
    "    for i in range(len(nwbs)):\n",
    "        if id in roi_tables[i].index:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ff21b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### for every match in the output, generate images which consist of ROI masks that supposedly match between sessions\n",
    "\n",
    "# roi_tables correspond to images based on index of nwb in nwds list\n",
    "roi_tables = [nwb.processing[\"ophys\"][\"image_segmentation\"][\"cell_specimen_table\"].to_dataframe() for nwb in nwbs]\n",
    "images = [np.zeros((512,512,3)).astype(\"uint8\") for nwb in nwbs]\n",
    "nway_matches = output[\"nway_matches\"]\n",
    "\n",
    "# for every list of matching IDs, generate a color, and add the ROI masks with those IDs to their respective images\n",
    "for i in range(len(nway_matches)):\n",
    "    match = nway_matches[i]\n",
    "    # unmatched ROIs will be shown white\n",
    "    if len(match) == 1:\n",
    "        color = [255,255,255]\n",
    "    else:\n",
    "        color = gen_color(i)\n",
    "\n",
    "    for id in match:\n",
    "        # n is the index of which image and which ROI table this ROI belongs to\n",
    "        n = get_image_num(id)        \n",
    "        roi_table = roi_tables[n]\n",
    "        # casting mask entry from roi table into np array\n",
    "        mask = roi_table[roi_table.index==id].image_mask.to_numpy()[0]\n",
    "        \n",
    "        # add mask to image with given color\n",
    "        images[n] = add_color_mask(images[n], mask, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926b212",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(images), figsize=(10,10))\n",
    "for i in range(len(images)):\n",
    "    axs[i].imshow(images[i])\n",
    "fig.suptitle(\"Matched ROIs between sessions\\n(White ROIs are unmatched)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
