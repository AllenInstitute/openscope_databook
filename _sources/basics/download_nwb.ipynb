{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b86eca",
   "metadata": {},
   "source": [
    "# Downloading an NWB File\n",
    "In order to analyze some data, you'll need to have some data. The [DANDI Archive](https://dandiarchive.org/) is used to store [NWB](https://www.nwb.org/) files in datasets called **dandisets** {cite}`Rubel2022`. Typically an NWB file contains the data for just one experimental session, while a dandiset contains all the related data files yielded from a project. This notebook allows you to download from public dandisets or private dandisets (called **embargoed** dandisets) via the [DANDI Python API](https://dandi.readthedocs.io/en/latest/modref/index.html). To download embargoed dandisets from DANDI, you will need to make an account on the DANDI Archive and must be given access by the owner of the dandiset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd33e5f",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "⚠️**Note: If running on a new environment, run this cell once and then restart the kernel**⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014235db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from databook_utils.dandi_utils import dandi_stream_open\n",
    "except:\n",
    "    !git clone https://github.com/AllenInstitute/openscope_databook.git\n",
    "    %cd openscope_databook\n",
    "    %pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f34eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dandi import dandiapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae798e1c",
   "metadata": {},
   "source": [
    "### Download Configuration\n",
    "Here you can configure the download. Browse the DANDI Archive for a dandiset you're interested in and use its ID in `dandiset_id`. Also set `download_loc` to the relative filepath of the directory you'd like to download to. If you're accessing an embargoed dandiset, you should set `authenticate` to True, and set `dandi_api_key` to your DANDI API Key, which can be found if you click on your profile icon in the top-right corner on the DANDI Archive website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67536d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = \"000021\"\n",
    "download_loc = \".\"\n",
    "authenticate = False\n",
    "dandi_api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a309c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got dandiset DANDI:000021/draft\n"
     ]
    }
   ],
   "source": [
    "if authenticate:\n",
    "    client = dandiapi.DandiAPIClient(token=dandi_api_key)\n",
    "else:\n",
    "    client = dandiapi.DandiAPIClient()\n",
    "my_dandiset = client.get_dandiset(dandiset_id)\n",
    "\n",
    "print(f\"Got dandiset {my_dandiset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ef8ac",
   "metadata": {},
   "source": [
    "### Downloading Just One File\n",
    "Set `dandi_filepath` to the path of the file you want to download within the dandiset. You can get this by navigating to the file you want to download on the DANDI Archive website and pressing on the `i` icon. There, you can copy the filepath from the field labeled `path`. Don't include a leading `/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c52a0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to download files with a progress bar\n",
    "from typing import Union, Iterator, Callable, Tuple, Dict\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "MAX_CHUNK_SIZE = int(os.environ.get(\"DANDI_MAX_CHUNK_SIZE\", 1024 * 1024 * 8))  \n",
    "\n",
    "def get_download_file_iter_with_steps(\n",
    "    file, chunk_size: int = MAX_CHUNK_SIZE\n",
    ") -> Tuple[Callable[[int], Iterator[bytes]], Dict[str, int]]:\n",
    "\n",
    "    url = file.base_download_url\n",
    "    steps_dict = {\"total_steps\": None}\n",
    "    result = file.client.session.get(url, stream=True)\n",
    "\n",
    "    total_size = int(result.headers.get('content-length', 0))\n",
    "    steps_dict[\"total_steps\"] = total_size // chunk_size\n",
    "    print(f\"Downloading {total_size} bytes in {steps_dict['total_steps']} steps\")\n",
    "\n",
    "    def downloader(start_at: int = 0) -> Iterator[bytes]:\n",
    "        headers = None\n",
    "        if start_at > 0:\n",
    "            headers = {\"Range\": f\"bytes={start_at}-\"}\n",
    "        result = file.client.session.get(url, stream=True, headers=headers)\n",
    "        result.raise_for_status()\n",
    "        for chunk in result.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:  \n",
    "                yield chunk\n",
    "\n",
    "    return downloader, steps_dict\n",
    "\n",
    "def download_with_progressbar(\n",
    "    file, filepath: Union[str, Path], chunk_size: int = MAX_CHUNK_SIZE\n",
    ") -> None:\n",
    "    downloader, steps_dict = get_download_file_iter_with_steps(file)\n",
    "    with open(filepath, \"wb\") as fp:\n",
    "        for chunk in tqdm(downloader(0), total=steps_dict[\"total_steps\"], unit=\"chunk\", unit_scale=True, unit_divisor=1024):\n",
    "            fp.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe9aa40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandi_filepath = \"sub-699733573/sub-699733573_ses-715093703.nwb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c176c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dandi_filepath.split(\"/\")[-1]\n",
    "filepath = f\"{download_loc}/{filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a110beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2856232912 bytes in 340 steps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739bb16b17f84c9aad57c5680cec33e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/340 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file to ./sub-699733573_ses-715093703.nwb\n"
     ]
    }
   ],
   "source": [
    "file = my_dandiset.get_asset_by_path(dandi_filepath)\n",
    "# this may take awhile, especially if the file to download is large\n",
    "download_with_progressbar(file, filepath)\n",
    "\n",
    "print(f\"Downloaded file to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85a038",
   "metadata": {},
   "source": [
    "### Downloading Entire Dandiset\n",
    "If you'd like to do a lot of work with the files in a dandiset, you might want to download the entire thing or some portion of the dandiset. Be prepared, though; This could take a significant amount of space on your drive and a significant amount of time. If you want to just download all the files within a directory of the dandiset, you can set the first argument of `download_directory` below to a more specific path within the dandiset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c42049e",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded directory to ./000021\n"
     ]
    }
   ],
   "source": [
    "# patience isn't just a virtue, it's a requirement\n",
    "my_dandiset.download_directory(\"\", f\"{download_loc}/{dandiset_id}\")\n",
    "\n",
    "print(f\"Downloaded directory to {download_loc}/{dandiset_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
